"""
èµ„æºåŒ…ç®¡ç†æ¨¡å—
ä¸“é—¨ä¸º Bukkit æ’ä»¶æä¾›èµ„æºåŒ…ä¸‹è½½æœåŠ¡
"""

import os
import json
import hashlib
import time
import zipfile
import tempfile
import threading
import asyncio
from pathlib import Path
from typing import Dict, List, Optional
from dataclasses import dataclass
import aiohttp
from aiohttp import web

# æ·»åŠ æ–‡ä»¶ç›‘æ§ç›¸å…³å¯¼å…¥
try:
    from watchdog.observers import Observer
    from watchdog.events import FileSystemEventHandler, FileSystemEvent
    WATCHDOG_AVAILABLE = True
except ImportError:
    WATCHDOG_AVAILABLE = False
    print("âš ï¸ watchdog åº“æœªå®‰è£…ï¼Œæ–‡ä»¶ç›‘æ§åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚è¯·è¿è¡Œ: pip install watchdog")


@dataclass
class ResourcePack:
    """èµ„æºåŒ…ä¿¡æ¯ç±»"""
    name: str
    path: Path
    description: str
    pack_format: int
    size: int
    hash: str
    last_modified: float
    is_directory: bool = False
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼ŒåŒ…å« Bukkit éœ€è¦çš„å­—æ®µ"""
        return {
            "name": self.name,
            "description": self.description,
            "pack_format": self.pack_format,
            "size": self.size,
            "hash": self.hash,
            "last_modified": self.last_modified,
            "is_directory": self.is_directory,
            "download_url": f"/download/{self.name}",
            "hash_url": f"/hash/{self.name}"
        }


class PacksManager:
    """èµ„æºåŒ…ç®¡ç†å™¨ - ä¸“é—¨ä¸º Bukkit è®¾è®¡"""
    
    def __init__(self, config):
        """åˆå§‹åŒ–èµ„æºåŒ…ç®¡ç†å™¨"""
        self.config = config
        self.packs_directory = Path(config.get("packs.directory", "resourcepack"))
        self.packs = {}
        self.temp_dir = Path(tempfile.gettempdir()) / "prushka_resourcepacks"
        
        # ç¡®ä¿ä¸´æ—¶ç›®å½•å­˜åœ¨
        self.temp_dir.mkdir(parents=True, exist_ok=True)
        
        # æ–‡ä»¶ç›‘æ§ç›¸å…³é…ç½®
        self.file_monitor_enabled = config.get("packs.file_monitor", True)
        self.file_monitor_interval = config.get("packs.file_monitor_interval", 1.0)  # ç§’
        self.observer = None
        self.file_monitor_thread = None
        self.last_scan_time = 0
        self.scan_cooldown = config.get("packs.scan_cooldown", 2.0)  # æ‰«æå†·å´æ—¶é—´ï¼ˆç§’ï¼‰
        
        # æ·»åŠ åœæ­¢æ ‡å¿—
        self._stop_monitoring = False
        
        # æ‰«æèµ„æºåŒ…
        self.scan_packs()
        
        # å¯åŠ¨æ–‡ä»¶ç›‘æ§
        if self.file_monitor_enabled and WATCHDOG_AVAILABLE:
            self.start_file_monitoring()
        elif self.file_monitor_enabled and not WATCHDOG_AVAILABLE:
            print("âš ï¸ æ–‡ä»¶ç›‘æ§åŠŸèƒ½å·²å¯ç”¨ä½† watchdog åº“æœªå®‰è£…")
            print("ğŸ’¡ è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…: pip install watchdog")
    
    def start_file_monitoring(self):
        """å¯åŠ¨æ–‡ä»¶ç›‘æ§"""
        if not WATCHDOG_AVAILABLE:
            return
            
        try:
            # é‡ç½®åœæ­¢æ ‡å¿—
            self._stop_monitoring = False
            
            # åˆ›å»ºæ–‡ä»¶ç³»ç»Ÿäº‹ä»¶å¤„ç†å™¨
            event_handler = ResourcePackFileHandler(self)
            
            # åˆ›å»ºè§‚å¯Ÿè€…
            self.observer = Observer()
            self.observer.schedule(event_handler, str(self.packs_directory), recursive=True)
            
            # å¯åŠ¨ç›‘æ§
            self.observer.start()
            print(f"ğŸ” æ–‡ä»¶ç›‘æ§å·²å¯åŠ¨ï¼Œç›‘æ§ç›®å½•: {self.packs_directory}")
            
        except Exception as e:
            print(f"âŒ å¯åŠ¨æ–‡ä»¶ç›‘æ§å¤±è´¥: {e}")
    
    def stop_file_monitoring(self):
        """åœæ­¢æ–‡ä»¶ç›‘æ§"""
        if self.observer:
            try:
                # è®¾ç½®åœæ­¢æ ‡å¿—
                self._stop_monitoring = True
                
                # ç«‹å³åœæ­¢è§‚å¯Ÿè€…
                self.observer.stop()
                
                # ç­‰å¾…è§‚å¯Ÿè€…çº¿ç¨‹ç»“æŸï¼Œä½†è®¾ç½®è¶…æ—¶
                self.observer.join(timeout=1.0)
                
                # å¦‚æœè¶…æ—¶ï¼Œå¼ºåˆ¶æ¸…ç†
                if self.observer.is_alive():
                    print("âš ï¸ æ–‡ä»¶ç›‘æ§çº¿ç¨‹è¶…æ—¶ï¼Œå¼ºåˆ¶æ¸…ç†")
                    # åœ¨Pythonä¸­æ— æ³•å¼ºåˆ¶æ€æ­»çº¿ç¨‹ï¼Œä½†æˆ‘ä»¬å¯ä»¥æ ‡è®°ä¸ºåœæ­¢
                
                print("ğŸ” æ–‡ä»¶ç›‘æ§å·²åœæ­¢")
                
            except Exception as e:
                print(f"âŒ åœæ­¢æ–‡ä»¶ç›‘æ§å¤±è´¥: {e}")
    
    def schedule_rescan(self):
        """è®¡åˆ’é‡æ–°æ‰«æèµ„æºåŒ…ï¼ˆå¸¦å†·å´æ—¶é—´ï¼‰"""
        # æ£€æŸ¥æ˜¯å¦å·²åœæ­¢ç›‘æ§
        if self._stop_monitoring:
            return
            
        current_time = time.time()
        if current_time - self.last_scan_time >= self.scan_cooldown:
            self.last_scan_time = current_time
            
            # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œæ‰«æï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
            def delayed_scan():
                # å†æ¬¡æ£€æŸ¥åœæ­¢æ ‡å¿—
                if self._stop_monitoring:
                    return
                    
                time.sleep(0.5)  # çŸ­æš‚å»¶è¿Ÿï¼Œç¡®ä¿æ–‡ä»¶æ“ä½œå®Œæˆ
                
                # æœ€ç»ˆæ£€æŸ¥åœæ­¢æ ‡å¿—
                if not self._stop_monitoring:
                    self.scan_packs()
            
            scan_thread = threading.Thread(target=delayed_scan, daemon=True)
            scan_thread.start()
            print("ğŸ”„ æ£€æµ‹åˆ°æ–‡ä»¶å˜åŒ–ï¼Œè®¡åˆ’é‡æ–°æ‰«æèµ„æºåŒ…...")
    
    def scan_packs(self) -> None:
        """æ‰«æèµ„æºåŒ…ç›®å½•"""
        try:
            old_packs = set(self.packs.keys())
            self.packs.clear()
            print(f"ğŸ” å¼€å§‹æ‰«æèµ„æºåŒ…ç›®å½•: {self.packs_directory.absolute()}")
            
            # é¦–å…ˆæ£€æŸ¥èµ„æºåŒ…ç›®å½•æœ¬èº«æ˜¯å¦æ˜¯ä¸€ä¸ªèµ„æºåŒ…
            if self._is_resource_pack_directory(self.packs_directory):
                print(f"ğŸ“ å‘ç°æ ¹ç›®å½•èµ„æºåŒ…: {self.packs_directory.name}")
                pack = self._load_directory_pack(self.packs_directory)
                if pack:
                    self.packs[pack.name] = pack
                    print(f"âœ… åŠ è½½æ ¹ç›®å½•èµ„æºåŒ…æˆåŠŸ: {pack.name}")
            
            # ç„¶åæ‰«æå­ç›®å½•å’Œæ–‡ä»¶
            for item in self.packs_directory.iterdir():
                if item.is_file() and item.suffix == '.zip':
                    # å¤„ç† .zip æ–‡ä»¶
                    pack = self._load_zip_pack(item)
                    if pack:
                        self.packs[pack.name] = pack
                        print(f"ğŸ“¦ å‘ç° ZIP èµ„æºåŒ…: {pack.name}")
                elif item.is_dir() and self._is_resource_pack_directory(item):
                    # å¤„ç†å­ç›®å½•èµ„æºåŒ…
                    pack = self._load_directory_pack(item)
                    if pack:
                        self.packs[pack.name] = pack
                        print(f"ğŸ“ å‘ç°å­ç›®å½•èµ„æºåŒ…: {pack.name}")
            
            new_packs = set(self.packs.keys())
            
            # æ£€æŸ¥å˜åŒ–
            added = new_packs - old_packs
            removed = old_packs - new_packs
            
            if added:
                print(f"âœ¨ æ–°å¢èµ„æºåŒ…: {', '.join(added)}")
            if removed:
                print(f"ğŸ—‘ï¸ ç§»é™¤èµ„æºåŒ…: {', '.join(removed)}")
            
            print(f"âœ… æ‰«æå®Œæˆï¼Œå…±å‘ç° {len(self.packs)} ä¸ªèµ„æºåŒ…")
            
        except Exception as e:
            print(f"âŒ æ‰«æèµ„æºåŒ…å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def _is_resource_pack_directory(self, dir_path: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„èµ„æºåŒ…ç›®å½•"""
        pack_mcmeta = dir_path / "pack.mcmeta"
        return pack_mcmeta.exists() and pack_mcmeta.is_file()
    
    def _load_zip_pack(self, pack_path: Path) -> Optional[ResourcePack]:
        """åŠ è½½ .zip èµ„æºåŒ…ä¿¡æ¯"""
        try:
            # è·å–åŸºæœ¬ä¿¡æ¯
            stat = pack_path.stat()
            name = pack_path.stem
            size = stat.st_size
            last_modified = stat.st_mtime
            
            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
            file_hash = self._calculate_file_hash(pack_path)
            
            # å°è¯•è¯»å– pack.mcmeta ä¿¡æ¯
            description = f"Resource Pack: {name}"
            pack_format = 22
            
            try:
                with zipfile.ZipFile(pack_path, 'r') as zip_file:
                    if 'pack.mcmeta' in zip_file.namelist():
                        mcmeta_content = zip_file.read('pack.mcmeta').decode('utf-8')
                        pack_info = self._parse_pack_mcmeta(mcmeta_content)
                        if pack_info:
                            description = pack_info.get('description', description)
                            pack_format = pack_info.get('pack_format', pack_format)
            except Exception as e:
                print(f"âš ï¸ è¯»å– {pack_path} çš„ pack.mcmeta å¤±è´¥: {e}")
            
            return ResourcePack(
                name=name,
                path=pack_path,
                description=description,
                pack_format=pack_format,
                size=size,
                hash=file_hash,
                last_modified=last_modified,
                is_directory=False
            )
            
        except Exception as e:
            print(f"âŒ åŠ è½½ .zip èµ„æºåŒ…å¤±è´¥ {pack_path}: {e}")
            return None
    
    def _load_directory_pack(self, dir_path: Path) -> Optional[ResourcePack]:
        """åŠ è½½ç›®å½•èµ„æºåŒ…ä¿¡æ¯"""
        try:
            # è·å–åŸºæœ¬ä¿¡æ¯
            name = dir_path.name
            last_modified = dir_path.stat().st_mtime
            
            # è¯»å– pack.mcmeta ä¿¡æ¯
            pack_mcmeta_path = dir_path / "pack.mcmeta"
            description = f"Resource Pack: {name}"
            pack_format = 22
            
            try:
                with open(pack_mcmeta_path, 'r', encoding='utf-8') as f:
                    mcmeta_content = f.read()
                    pack_info = self._parse_pack_mcmeta(mcmeta_content)
                    if pack_info:
                        description = pack_info.get('description', description)
                        pack_format = pack_info.get('pack_format', pack_format)
            except Exception as e:
                print(f"âš ï¸ è¯»å– {pack_mcmeta_path} å¤±è´¥: {e}")
            
            # è®¡ç®—ç›®å½•å¤§å°å’Œå“ˆå¸Œ
            size = self._calculate_directory_size(dir_path)
            dir_hash = self._calculate_directory_hash(dir_path)
            
            return ResourcePack(
                name=name,
                path=dir_path,
                description=description,
                pack_format=pack_format,
                size=size,
                hash=dir_hash,
                last_modified=last_modified,
                is_directory=True
            )
            
        except Exception as e:
            print(f"âŒ åŠ è½½ç›®å½•èµ„æºåŒ…å¤±è´¥ {dir_path}: {e}")
            return None
    
    def _parse_pack_mcmeta(self, content: str) -> Optional[Dict]:
        """è§£æ pack.mcmeta æ–‡ä»¶å†…å®¹"""
        try:
            data = json.loads(content)
            pack_info = data.get('pack', {})
            return {
                'description': pack_info.get('description', ''),
                'pack_format': pack_info.get('pack_format', 22)
            }
        except Exception as e:
            print(f"âš ï¸ è§£æ pack.mcmeta å¤±è´¥: {e}")
            return None
    
    def _calculate_directory_size(self, dir_path: Path) -> int:
        """è®¡ç®—ç›®å½•å¤§å°"""
        total_size = 0
        try:
            for item in dir_path.rglob('*'):
                if item.is_file():
                    total_size += item.stat().st_size
        except Exception as e:
            print(f"âš ï¸ è®¡ç®—ç›®å½•å¤§å°å¤±è´¥ {dir_path}: {e}")
        return total_size
    
    def _calculate_directory_hash(self, dir_path: Path) -> str:
        """è®¡ç®—ç›®å½•å“ˆå¸Œå€¼ï¼ˆåŸºäºæ–‡ä»¶ä¿®æ”¹æ—¶é—´å’Œå¤§å°ï¼‰"""
        hash_md5 = hashlib.md5()
        try:
            # æ”¶é›†æ‰€æœ‰æ–‡ä»¶çš„ä¿¡æ¯
            file_infos = []
            for item in sorted(dir_path.rglob('*')):
                if item.is_file():
                    stat = item.stat()
                    file_infos.append(f"{item.relative_to(dir_path)}:{stat.st_mtime}:{stat.st_size}")
            
            # è®¡ç®—å“ˆå¸Œ
            content = "\n".join(file_infos).encode('utf-8')
            hash_md5.update(content)
            return hash_md5.hexdigest()
        except Exception as e:
            print(f"âš ï¸ è®¡ç®—ç›®å½•å“ˆå¸Œå¤±è´¥ {dir_path}: {e}")
            return ""
    
    def _calculate_file_hash(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼"""
        hash_md5 = hashlib.md5()
        try:
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except Exception as e:
            print(f"âš ï¸ è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥ {file_path}: {e}")
            return ""
    
    def get_pack(self, name: str) -> Optional[ResourcePack]:
        """è·å–æŒ‡å®šåç§°çš„èµ„æºåŒ…"""
        return self.packs.get(name)
    
    def get_all_packs(self) -> List[ResourcePack]:
        """è·å–æ‰€æœ‰èµ„æºåŒ…"""
        return list(self.packs.values())
    
    def get_pack_hash(self, name: str) -> Optional[str]:
        """è·å–èµ„æºåŒ…çš„ hash å€¼ï¼ˆBukkit éœ€è¦ï¼‰"""
        pack = self.get_pack(name)
        return pack.hash if pack else None
    
    async def serve_pack(self, name: str) -> Optional[web.FileResponse]:
        """æä¾›èµ„æºåŒ…ä¸‹è½½"""
        pack = self.get_pack(name)
        if not pack:
            return None
        
        if pack.is_directory:
            # åŠ¨æ€å‹ç¼©ç›®å½•
            zip_path = await self._create_zip_from_directory(pack.path, pack.name)
            if zip_path and zip_path.exists():
                return web.FileResponse(
                    path=zip_path,
                    headers={
                        'Content-Disposition': f'attachment; filename="{pack.name}.zip"',
                        'Content-Type': 'application/zip'
                    }
                )
            else:
                return None
        else:
            # ç›´æ¥è¿”å› .zip æ–‡ä»¶
            return web.FileResponse(
                path=pack.path,
                headers={
                    'Content-Disposition': f'attachment; filename="{pack.name}.zip"',
                    'Content-Type': 'application/zip'
                }
            )
    
    async def _create_zip_from_directory(self, dir_path: Path, pack_name: str) -> Optional[Path]:
        """ä»ç›®å½•åˆ›å»º zip æ–‡ä»¶"""
        try:
            # åˆ›å»ºä¸´æ—¶ zip æ–‡ä»¶
            zip_path = self.temp_dir / f"{pack_name}_{int(time.time())}.zip"
            
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                for item in dir_path.rglob('*'):
                    if item.is_file():
                        # è®¡ç®—ç›¸å¯¹è·¯å¾„
                        arcname = item.relative_to(dir_path)
                        zip_file.write(item, arcname)
            
            print(f"ğŸ“¦ å·²åˆ›å»ºä¸´æ—¶ zip æ–‡ä»¶: {zip_path}")
            return zip_path
            
        except Exception as e:
            print(f"âŒ åˆ›å»º zip æ–‡ä»¶å¤±è´¥ {dir_path}: {e}")
            return None

    def __del__(self):
        """ææ„å‡½æ•°ï¼Œç¡®ä¿åœæ­¢æ–‡ä»¶ç›‘æ§"""
        self.stop_file_monitoring()


class ResourcePackFileHandler(FileSystemEventHandler):
    """èµ„æºåŒ…æ–‡ä»¶ç³»ç»Ÿäº‹ä»¶å¤„ç†å™¨"""
    
    def __init__(self, packs_manager: PacksManager):
        self.packs_manager = packs_manager
        super().__init__()
    
    def on_created(self, event: FileSystemEvent):
        """æ–‡ä»¶/ç›®å½•åˆ›å»ºäº‹ä»¶"""
        if not event.is_directory and event.src_path.endswith('.zip'):
            print(f"ğŸ“¦ æ£€æµ‹åˆ°æ–°çš„ ZIP èµ„æºåŒ…: {event.src_path}")
            self.packs_manager.schedule_rescan()
        elif event.is_directory:
            # æ£€æŸ¥æ–°åˆ›å»ºçš„ç›®å½•æ˜¯å¦æ˜¯èµ„æºåŒ…
            dir_path = Path(event.src_path)
            if self.packs_manager._is_resource_pack_directory(dir_path):
                print(f"ğŸ“ æ£€æµ‹åˆ°æ–°çš„ç›®å½•èµ„æºåŒ…: {event.src_path}")
                self.packs_manager.schedule_rescan()
    
    def on_deleted(self, event: FileSystemEvent):
        """æ–‡ä»¶/ç›®å½•åˆ é™¤äº‹ä»¶"""
        if not event.is_directory and event.src_path.endswith('.zip'):
            print(f"ğŸ—‘ï¸ æ£€æµ‹åˆ° ZIP èµ„æºåŒ…è¢«åˆ é™¤: {event.src_path}")
            self.packs_manager.schedule_rescan()
        elif event.is_directory:
            print(f"ğŸ—‘ï¸ æ£€æµ‹åˆ°ç›®å½•è¢«åˆ é™¤: {event.src_path}")
            self.packs_manager.schedule_rescan()
    
    def on_modified(self, event: FileSystemEvent):
        """æ–‡ä»¶ä¿®æ”¹äº‹ä»¶"""
        if not event.is_directory:
            if event.src_path.endswith('.zip'):
                print(f"ğŸ“ æ£€æµ‹åˆ° ZIP èµ„æºåŒ…è¢«ä¿®æ”¹: {event.src_path}")
                self.packs_manager.schedule_rescan()
            elif event.src_path.endswith('pack.mcmeta'):
                print(f"ğŸ“ æ£€æµ‹åˆ° pack.mcmeta è¢«ä¿®æ”¹: {event.src_path}")
                self.packs_manager.schedule_rescan()
    
    def on_moved(self, event: FileSystemEvent):
        """æ–‡ä»¶/ç›®å½•ç§»åŠ¨äº‹ä»¶"""
        if not event.is_directory and (event.src_path.endswith('.zip') or event.dest_path.endswith('.zip')):
            print(f"ğŸ”„ æ£€æµ‹åˆ° ZIP èµ„æºåŒ…è¢«ç§»åŠ¨: {event.src_path} -> {event.dest_path}")
            self.packs_manager.schedule_rescan()
        elif event.is_directory:
            print(f"ğŸ”„ æ£€æµ‹åˆ°ç›®å½•è¢«ç§»åŠ¨: {event.src_path} -> {event.dest_path}")
            self.packs_manager.schedule_rescan()
