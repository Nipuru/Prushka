import os
import re
import json

from .st_parser import parse_st_file, find_all_st_files
from .st_validator import StValidator
from .config import Config

type_mapping = {
    "int32": "Int",
    "int64": "Long",
    "float32": "Float",
    "float64": "Double",
    "bool": "Boolean",
    "string": "String",
}

sheet_template = """
// This file is auto-generated. DO NOT EDIT.
// Generated by tool
package server.common.sheet

data class <name>(
<fields>
)

<extentions>

internal object <name>Holder : SheetHolder<<name>> {
<maps>
    override fun put(value: <name>) {
<mappings>
    }

    override fun clear() {
<clearings>
    }

    override fun type(): Class<<name>> {
        return <name>::class.java
    }
}
"""

def generate_code():
    st_files = find_all_st_files(Config.excel_path)

    print('开始解析所有表...')

    # 先解析所有表，构建 all_tables 字典
    all_tables = {}
    parsed_files = {}  # {file_path: StParser}
    for st_file_path in st_files:
        try:
            st = parse_st_file(st_file_path)
            parsed_files[st_file_path] = st
            if st.table_name:
                all_tables[st.table_name] = st
        except Exception as e:
            print(f'\n解析失败: {st_file_path}')
            print(f'  错误: {str(e)}')

    print('开始语法检查...')

    validation_failed = False
    for st_file_path, st in parsed_files.items():
        validator = StValidator(st, st_file_path, all_tables)
        is_valid = validator.validate()

        if not is_valid or validator.warnings:
            print(f'\n{validator.get_report()}')
            if not is_valid:
                validation_failed = True

    if validation_failed:
        print('语法检查失败，停止代码生成')
        return

    print('语法检查通过，开始生成代码...')

    all_metadata = []  # 收集所有表的元数据（使用列表）

    for st_file_path, st in parsed_files.items():
        print('正在生成 %s' % (st_file_path))

        if not st.table_name:
            print('st文件没有定义table')
            continue

        table_name = 'st_' + st.table_name
        class_name = snake_to_pascal(table_name)
        field_name = snake_to_camel(table_name)

        config = st.get_table_config()

        key = []
        vkey = []
        akey = []
        subkey = []

        for field in st.fields:

            field_camel = snake_to_camel(field['name'])
            kotlin_type = __kotlin_type(field['type'], all_tables)

            if config.get('key') == field['name']:
                key = [field_camel, kotlin_type]
            elif config.get('vkey') == field['name']:
                vkey = [field_camel, kotlin_type]
            elif config.get('akey') == field['name']:
                akey = [field_camel, kotlin_type]
            elif config.get('subkey') == field['name']:
                subkey = [field_camel, kotlin_type]

        if key and akey:
            print('%s表同时存在key和akey' % (table_name))
            continue

        maps = []
        extentions = []
        clearings = []

        if key:
            maps.append(f"    val {field_name}Map = mutableMapOf<{key[1]}, {class_name}>()")
            extentions.append(f"fun Sheet.getAll{class_name}(): Map<{key[1]}, {class_name}> {{\n    check()\n    return {class_name}Holder.{field_name}Map\n}}")
            extentions.append(f"fun Sheet.get{class_name}({key[0]}: {key[1]}): {class_name}? {{\n    check()\n    return {class_name}Holder.{field_name}Map[{key[0]}]\n}}")
            clearings.append(f"        {field_name}Map.clear()")

        if vkey:
            maps.append(f"    val {field_name}VMap= mutableMapOf<{vkey[1]}, {class_name}>()")
            extentions.append(f"fun Sheet.get{class_name}ById({vkey[0]}: {vkey[1]}): {class_name}? {{\n    check()\n    return {class_name}Holder.{field_name}VMap[{vkey[0]}]\n}}")
            clearings.append(f"        {field_name}VMap.clear()")

        if akey:
            maps.append(f"    val {field_name}AMap = mutableMapOf<{akey[1]}, MutableList<{class_name}>>()")
            extentions.append(f"fun Sheet.get{class_name}s({akey[0]}: {akey[1]}): List<{class_name}> {{\n    check()\n    return {class_name}Holder.{field_name}AMap[{akey[0]}] ?: emptyList()\n}}")
            clearings.append(f"        {field_name}AMap.clear()")

            if subkey:
                maps.append(f"    val {field_name}PMap = mutableMapOf<Pair<{akey[1]}, {subkey[1]}>, {class_name}>()")
                extentions.append(f"fun Sheet.get{class_name}({akey[0]}: {akey[1]}, {subkey[0]}: {subkey[1]}): {class_name}? {{\n    check()\n    return {class_name}Holder.{field_name}PMap[{akey[0]} to {subkey[0]}]\n}}")
                clearings.append(f"        {field_name}PMap.clear()")

        fields = []
        for field in st.fields:

            name = snake_to_camel(field['name'])
            field_type = field['type']
            typ = __kotlin_type(field_type, all_tables)
            comment = field.get('comment', '')

            # 如果是引用类型，在注释中添加引用信息
            if field_type.startswith('ref<'):
                if comment:
                    comment = f"{comment} {field_type}"
                else:
                    comment = field_type

            if comment:
                fields.append(f"    /** {comment} */\n    val {name}: {typ}")
            else:
                fields.append(f"    val {name}: {typ}")

        mappings = ""
        if key:
            mappings += f"        {field_name}Map[value.{key[0]}] = value\n"
        if vkey:
            mappings += f"        {field_name}VMap[value.{vkey[0]}] = value\n"
        if akey:
            mappings += f"        {field_name}AMap.getOrPut(value.{akey[0]}) {{ mutableListOf() }}.add(value)\n"
            if subkey:
                mappings += f"        {field_name}PMap[value.{akey[0]} to value.{subkey[0]}] = value\n"
        mappings = mappings.rstrip()

        sheet_code = sheet_template.replace('<name>', class_name)
        sheet_code = sheet_code.replace('<fields>', ',\n'.join(fields))
        sheet_code = sheet_code.replace('<maps>', '\n'.join(maps))
        sheet_code = sheet_code.replace('<extentions>', '\n\n'.join(extentions))
        sheet_code = sheet_code.replace('<mappings>',  mappings)
        sheet_code = sheet_code.replace('<clearings>', '\n'.join(clearings))

        sheet_path = '%s/server-common/src/main/kotlin/server/common/sheet/%s.kt' % (Config.code_path, class_name)
        write_file(sheet_path, sheet_code)

        # 收集 JSON 元信息
        metadata = export_sheet_metadata(st, table_name, all_tables)
        all_metadata.append(metadata)  # 添加到列表

    # 统一写入所有表的元数据到一个文件
    metadata_json_path = '%s/server-common/src/main/resources/sheet_metadata.json' % (Config.code_path)
    print('正在保存 %s' % (metadata_json_path))
    os.makedirs(os.path.dirname(metadata_json_path), exist_ok=True)
    with open(metadata_json_path, 'w', encoding='utf-8') as f:
        json.dump(all_metadata, f, ensure_ascii=False, indent=2)
    print('表格元数据已生成 (%d 个表)' % len(all_metadata))

def __kotlin_type(column_type, all_tables=None):
    original_type = column_type

    # 处理 ref<表名.字段> 类型
    if column_type.startswith('ref<'):
        match = re.match(r'ref<(\w+)\.(\w+)>', column_type)
        if match and all_tables:
            ref_table = match.group(1)
            ref_field = match.group(2)
            if ref_table in all_tables:
                ref_st = all_tables[ref_table]
                for f in ref_st.fields:
                    if f['name'] == ref_field:
                        # 递归获取引用字段的实际类型
                        return __kotlin_type(f['type'], all_tables)
        raise ValueError(f"无法解析引用类型: {original_type}")

    is_array = column_type.startswith("[]")
    if is_array:
        element_type = column_type[2:]

        base_kotlin_type = type_mapping.get(element_type)
        if base_kotlin_type is None:
            raise ValueError(f"不支持的数据类型: {original_type}")

        kotlin_type = f"List<{base_kotlin_type}>"
    else:
        kotlin_type = type_mapping.get(column_type)
        if kotlin_type is None:
            raise ValueError(f"不支持的数据类型: {original_type}")

    return kotlin_type

def snake_to_pascal(snake_str):
    return ''.join(word.capitalize() for word in snake_str.split('_'))

def snake_to_camel(snake_str):
    words = snake_str.split('_')
    return words[0] + ''.join(word.capitalize() for word in words[1:])

def write_file(path, context):
    print('正在保存 %s' % (path))
    os.makedirs(os.path.dirname(path), exist_ok=True)
    f = open( path, 'w', encoding='utf-8' )
    f.write(  context.strip() )
    f.close()

def parse_data_value(value_str, field_type):
    """将字符串值解析为对应的 Python 数据类型"""
    value_str = value_str.strip()

    # 处理数组类型
    if field_type.startswith('[]'):
        if value_str.startswith('[') and value_str.endswith(']'):
            # 解析数组内容
            array_content = value_str[1:-1].strip()
            if not array_content:
                return []
            # 简单分割，支持基本类型数组
            elements = [v.strip().strip('"') for v in array_content.split(',')]
            element_type = field_type[2:]
            return [parse_data_value(elem, element_type) for elem in elements]
        return []

    # 处理基础类型
    if field_type == 'int32' or field_type == 'int64':
        try:
            return int(value_str)
        except ValueError:
            return 0
    elif field_type == 'float32' or field_type == 'float64':
        try:
            return float(value_str)
        except ValueError:
            return 0.0
    elif field_type == 'bool':
        return value_str.lower() in ('true', '1', 'yes')
    else:  # string 或 ref 类型
        # 移除可能的引号
        if value_str.startswith('"') and value_str.endswith('"'):
            return value_str[1:-1]
        return value_str

def export_sheet_metadata(st, table_name, all_tables):
    """导出表结构为 JSON 格式，返回元数据字典"""
    config = st.get_table_config()

    # 构建 JSON 数据结构
    metadata = {
        'table_name': st.table_name,
        'table_comment': st.table_comment,  # table的中文名称注释
        'holder_class': 'server.common.sheet.St' + snake_to_pascal(st.table_name) + 'Holder',
        'indexes': {
            'key': config.get('key'),
            'vkey': config.get('vkey'),
            'akey': config.get('akey'),
            'subkey': config.get('subkey')
        },
        'unique': config.get('unique', []),
        'fields': [],
        'data': []
    }

    # 添加字段信息
    for field in st.fields:
        field_info = {
            'name': field['name'],
            'type': field['type'],
            'comment': field.get('comment', '')
        }

        # 如果是引用类型，尝试解析出实际类型
        if field['type'].startswith('ref<'):
            match = re.match(r'ref<(\w+)\.(\w+)>', field['type'])
            if match and all_tables:
                ref_table = match.group(1)
                ref_field = match.group(2)
                if ref_table in all_tables:
                    ref_st = all_tables[ref_table]
                    for f in ref_st.fields:
                        if f['name'] == ref_field:
                            field_info['resolved_type'] = f['type']
                            break

        metadata['fields'].append(field_info)

    # 解析预制数据
    for row_str in st.data_rows:
        parsed_row = st.parse_data_row(row_str)
        # 转换数据类型
        typed_row = []
        for i, value_str in enumerate(parsed_row):
            if i < len(st.fields):
                field_type = st.fields[i]['type']
                # 如果是引用类型，使用解析后的实际类型
                if field_type.startswith('ref<'):
                    match = re.match(r'ref<(\w+)\.(\w+)>', field_type)
                    if match and all_tables:
                        ref_table = match.group(1)
                        ref_field = match.group(2)
                        if ref_table in all_tables:
                            ref_st = all_tables[ref_table]
                            for f in ref_st.fields:
                                if f['name'] == ref_field:
                                    field_type = f['type']
                                    break

                typed_value = parse_data_value(value_str, field_type)
                typed_row.append(typed_value)
            else:
                typed_row.append(value_str.strip().strip('"'))

        metadata['data'].append(typed_row)

    return metadata
